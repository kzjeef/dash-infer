diff --git a/.gitmodules b/.gitmodules
deleted file mode 100644
index 1234567..0000000
--- a/.gitmodules
+++ /dev/null
@@ -1,3 +0,0 @@
-[submodule "csrc/cutlass"]
-	path = csrc/cutlass
-	url = https://github.com/NVIDIA/cutlass.git
diff --git a/csrc/CMakeLists.txt b/csrc/CMakeLists.txt
new file mode 100644
index 0000000..abcdef0
--- /dev/null
+++ b/csrc/CMakeLists.txt
@@ -0,0 +1,118 @@
+cmake_minimum_required(VERSION 3.18)
+
+project(FLASHMLA LANGUAGES CXX CUDA)
+option(CMAKE_EXPORT_COMPILE_COMMANDS ON)
+
+set(FLASHMLA_CUDA_VERSION
+    "12.3"
+    CACHE STRING "cuda version")
+set(FLASHMLA_GPU_ARCHS
+    "90"
+    CACHE STRING "gpu archs")
+set(FLASHMLA_USE_CUDA_STATIC
+    OFF
+    CACHE BOOL "use static CUDA")
+
+# Generate SASS for each architecture
+set(GENCODES "")
+foreach(arch ${FLASHMLA_GPU_ARCHS})
+  list(APPEND GENCODES "${arch}-real")
+endforeach()
+# Generate PTX for the lowest arch for forward compatibility
+list(GET FLASHMLA_GPU_ARCHS 0 LOWEST_GPU_ARCH)
+string(REGEX MATCH "^[0-9]+" LOWEST_GPU_ARCH_BASE "${LOWEST_GPU_ARCH}")
+list(APPEND GENCODES "${LOWEST_GPU_ARCH_BASE}-virtual")
+set(CMAKE_CUDA_ARCHITECTURES ${GENCODES})
+
+find_package(CUDAToolkit ${FLASHMLA_CUDA_VERSION} EXACT REQUIRED)
+
+if(FLASHMLA_USE_CUDA_STATIC)
+  set(FLASHMLA_CUDA_CUDART CUDA::cudart_static)
+else()
+  set(FLASHMLA_CUDA_CUDART CUDA::cudart)
+endif()
+
+# Use external cutlass
+find_package(NvidiaCutlass PATHS ${CUTLASS_INSTALL_PATH})
+set(CUTLASS_INCLUDE_DIR ${CUTLASS_INSTALL_PATH}/include)
+
+set(FLASHMLA_ROOT ${PROJECT_SOURCE_DIR})
+set(FLASHMLA_INCLUDE_DIR ${PROJECT_SOURCE_DIR} ${PROJECT_SOURCE_DIR}/..)
+
+# Collect SM90 decode kernel sources
+file(GLOB_RECURSE FLASHMLA_SM90_DECODE_SRCS
+  ${FLASHMLA_ROOT}/sm90/decode/*.cu
+)
+
+# Collect common decode sources (combine, sched meta)
+file(GLOB_RECURSE FLASHMLA_COMMON_DECODE_SRCS
+  ${FLASHMLA_ROOT}/smxx/decode/*.cu
+)
+
+# The C API wrapper
+set(FLASHMLA_API_SRCS ${FLASHMLA_ROOT}/flash_mla_c_api.cu)
+
+set(FLASHMLA_SRCS
+  ${FLASHMLA_SM90_DECODE_SRCS}
+  ${FLASHMLA_COMMON_DECODE_SRCS}
+  ${FLASHMLA_API_SRCS}
+)
+
+# Remove backward/training files if any
+file(GLOB_RECURSE FLASHMLA_BWD_SRCS ${FLASHMLA_ROOT}/*_bwd_*.cu)
+foreach(file ${FLASHMLA_BWD_SRCS})
+  list(REMOVE_ITEM FLASHMLA_SRCS "${file}")
+endforeach()
+
+message(STATUS "FlashMLA build source list: ${FLASHMLA_SRCS}")
+
+list(APPEND FLASHMLA_CUDA_FLAGS "-U__CUDA_NO_HALF_OPERATORS__")
+list(APPEND FLASHMLA_CUDA_FLAGS "-U__CUDA_NO_HALF_CONVERSIONS__")
+list(APPEND FLASHMLA_CUDA_FLAGS "-U__CUDA_NO_HALF2_OPERATORS__")
+list(APPEND FLASHMLA_CUDA_FLAGS "-U__CUDA_NO_BFLOAT16_CONVERSIONS__")
+list(APPEND FLASHMLA_CUDA_FLAGS "--expt-relaxed-constexpr")
+list(APPEND FLASHMLA_CUDA_FLAGS "--expt-extended-lambda")
+list(APPEND FLASHMLA_CUDA_FLAGS "-O3")
+list(APPEND FLASHMLA_CUDA_FLAGS "--use_fast_math")
+list(APPEND FLASHMLA_CUDA_FLAGS "-t 4")
+list(APPEND FLASHMLA_CUDA_FLAGS "-std=c++20")
+list(APPEND FLASHMLA_CUDA_FLAGS "--maxrregcount=255")
+
+# Create an object library with the source files
+add_library(flash-mla-obj OBJECT ${FLASHMLA_SRCS})
+set_target_properties(flash-mla-obj PROPERTIES CXX_STANDARD 20 CUDA_STANDARD 20)
+set_target_properties(flash-mla-obj PROPERTIES POSITION_INDEPENDENT_CODE ON)
+target_compile_options(flash-mla-obj PRIVATE $<$<COMPILE_LANGUAGE:CUDA>:${FLASHMLA_CUDA_FLAGS}>)
+target_include_directories(flash-mla-obj PUBLIC
+  ${FLASHMLA_INCLUDE_DIR}
+  ${CUTLASS_INCLUDE_DIR}
+  ${FLASHMLA_ROOT}/kerutils
+)
+target_compile_definitions(flash-mla-obj PRIVATE FLASHMLA_C_API)
+
+# Create STATIC library from the object files
+add_library(flash-mla_static STATIC $<TARGET_OBJECTS:flash-mla-obj>)
+set_target_properties(flash-mla_static PROPERTIES OUTPUT_NAME "flash-mla")
+target_link_libraries(flash-mla_static PRIVATE ${FLASHMLA_CUDA_CUDART})
+
+# Create SHARED library from the object files
+add_library(flash-mla SHARED $<TARGET_OBJECTS:flash-mla-obj>)
+target_link_libraries(flash-mla PRIVATE ${FLASHMLA_CUDA_CUDART})
+
+# Install both static and shared libraries
+install(TARGETS flash-mla_static flash-mla
+    EXPORT flash-mla
+)
+
+# Install the C API header
+install(FILES ${FLASHMLA_ROOT}/flash_mla_c_api.h
+    DESTINATION include
+)
diff --git a/csrc/flash_mla_c_api.h b/csrc/flash_mla_c_api.h
new file mode 100644
index 0000000..1234567
--- /dev/null
+++ b/csrc/flash_mla_c_api.h
@@ -0,0 +1,76 @@
+// C API for FlashMLA - stripped of PyTorch dependencies
+// This header exposes the FlashMLA decode kernel for integration
+// into inference engines without PyTorch.
+#pragma once
+
+#include <cuda.h>
+#include <cuda_runtime.h>
+#include <stdint.h>
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+// FlashMLA dense decode parameters (mirrors DenseAttnDecodeParams)
+struct FlashMLADecodeParams {
+    // Dimensions
+    int batch_size;
+    int num_heads_q;       // number of query heads (e.g., 128)
+    int num_heads_kv;      // number of KV heads (1 for MQA in DeepSeek V3)
+    int head_dim_qk;       // query/key head dim (e.g., 576 = 512 + 64)
+    int head_dim_v;        // value head dim (e.g., 512)
+    int page_block_size;   // page block size (64)
+
+    // Input pointers (device memory)
+    const void* q;             // [batch, 1, num_heads_q, head_dim_qk]  bf16/fp16
+    const void* kv_cache;      // [num_blocks, page_block_size, num_heads_kv, head_dim_qk]  bf16/fp16
+    void* output;              // [batch, 1, num_heads_q, head_dim_v]   bf16/fp16
+
+    // Paged attention tables (device memory)
+    const int* block_table;    // [batch, max_num_blocks_per_seq]
+    const int* cache_seqlens;  // [batch]
+    int block_table_batch_stride;  // stride for block_table
+
+    // Softmax
+    float softmax_scale;
+    int is_causal;
+
+    // Data type: 0 = bf16, 1 = fp16
+    int dtype;
+
+    // Workspace for split-KV (allocated by caller)
+    void* splitkv_out;         // workspace buffer
+    float* splitkv_lse;        // workspace buffer
+    void* tile_scheduler_metadata;  // scheduling metadata (persistent, allocated by caller)
+    int* num_splits;           // number of splits (persistent, allocated by caller)
+    int metadata_initialized;  // 0 = first call, 1 = reuse metadata
+
+    // CUDA device properties
+    const cudaDeviceProp* dprop;
+};
+
+// Initialize FlashMLA decode parameters to zero
+void flash_mla_decode_clear_params(struct FlashMLADecodeParams* params);
+
+// Run FlashMLA dense decode kernel
+// Returns 0 on success, non-zero on error
+int flash_mla_dense_decode(struct FlashMLADecodeParams* params, cudaStream_t stream);
+
+// Calculate workspace sizes needed for split-KV
+// Returns sizes in bytes for splitkv_out, splitkv_lse, tile_scheduler_metadata, num_splits
+void flash_mla_get_workspace_sizes(
+    int batch_size,
+    int num_heads_q,
+    int head_dim_v,
+    int max_seqlen_kv,
+    int page_block_size,
+    size_t* splitkv_out_bytes,
+    size_t* splitkv_lse_bytes,
+    size_t* metadata_bytes,
+    size_t* num_splits_bytes
+);
+
+#ifdef __cplusplus
+}
+#endif
diff --git a/csrc/flash_mla_c_api.cu b/csrc/flash_mla_c_api.cu
new file mode 100644
index 0000000..2345678
--- /dev/null
+++ b/csrc/flash_mla_c_api.cu
@@ -0,0 +1,153 @@
+// C API implementation for FlashMLA
+// Bridges the C interface to the internal CUDA kernels
+
+#include "flash_mla_c_api.h"
+#include "params.h"
+#include "utils.h"
+
+#include <cuda_bf16.h>
+#include <cuda_fp16.h>
+#include <cstring>
+#include <cstdio>
+
+// Forward declarations of internal kernel launchers
+namespace flash_mla {
+
+// SM90 dense decode kernel launchers
+template <typename DType, int HEAD_DIM_QK>
+void run_dense_decode_splitkv(
+    DenseAttnDecodeParams& params,
+    cudaStream_t stream);
+
+// Combine kernel
+void run_combine(CombineParams& params, cudaStream_t stream);
+
+// Schedule metadata generation
+void run_get_decoding_sched_meta(
+    GetDecodeSchedMetaParams& params,
+    cudaStream_t stream);
+
+}  // namespace flash_mla
+
+extern "C" {
+
+void flash_mla_decode_clear_params(struct FlashMLADecodeParams* params) {
+    memset(params, 0, sizeof(struct FlashMLADecodeParams));
+}
+
+void flash_mla_get_workspace_sizes(
+    int batch_size,
+    int num_heads_q,
+    int head_dim_v,
+    int max_seqlen_kv,
+    int page_block_size,
+    size_t* splitkv_out_bytes,
+    size_t* splitkv_lse_bytes,
+    size_t* metadata_bytes,
+    size_t* num_splits_bytes
+) {
+    // Estimate max splits based on sequence length and block size
+    int max_num_blocks = (max_seqlen_kv + page_block_size - 1) / page_block_size;
+    // Each SM can handle a split; estimate conservatively
+    int max_splits = (max_num_blocks + 3) / 4;
+    if (max_splits < 1) max_splits = 1;
+    if (max_splits > 256) max_splits = 256;
+
+    // splitkv_out: [batch, max_splits, num_heads_q, head_dim_v] in bf16 (2 bytes)
+    *splitkv_out_bytes = (size_t)batch_size * max_splits * num_heads_q * head_dim_v * 2;
+    // splitkv_lse: [batch, max_splits, num_heads_q] in float
+    *splitkv_lse_bytes = (size_t)batch_size * max_splits * num_heads_q * sizeof(float);
+    // tile_scheduler_metadata: conservative estimate
+    *metadata_bytes = (size_t)batch_size * max_num_blocks * 32;  // DecodingSchedMeta is 32 bytes
+    // num_splits: [batch + 1] ints
+    *num_splits_bytes = (size_t)(batch_size + 1) * sizeof(int);
+}
+
+int flash_mla_dense_decode(struct FlashMLADecodeParams* params, cudaStream_t stream) {
+    if (!params || !params->q || !params->kv_cache || !params->output) {
+        return -1;
+    }
+
+    // Build internal DenseAttnDecodeParams
+    DenseAttnDecodeParams decode_params;
+    memset(&decode_params, 0, sizeof(decode_params));
+
+    decode_params.b = params->batch_size;
+    decode_params.s_q = 1;  // decode: single token
+    decode_params.h_q = params->num_heads_q;
+    decode_params.h_kv = params->num_heads_kv;
+    decode_params.d_qk = params->head_dim_qk;
+    decode_params.d_v = params->head_dim_v;
+    decode_params.page_block_size = params->page_block_size;
+
+    decode_params.q_ptr = params->q;
+    decode_params.kvcache_ptr = params->kv_cache;
+    decode_params.o_ptr = params->output;
+
+    decode_params.block_table = params->block_table;
+    decode_params.cache_seqlens = params->cache_seqlens;
+    decode_params.block_table_batch_stride = params->block_table_batch_stride;
+
+    decode_params.softmax_scale = params->softmax_scale;
+
+    // Strides for query: [batch, 1, num_heads_q, head_dim_qk]
+    decode_params.q_batch_stride = params->num_heads_q * params->head_dim_qk;
+    decode_params.q_head_stride = params->head_dim_qk;
+
+    // Strides for output: [batch, 1, num_heads_q, head_dim_v]
+    decode_params.o_batch_stride = params->num_heads_q * params->head_dim_v;
+    decode_params.o_head_stride = params->head_dim_v;
+
+    // KV cache strides: [num_blocks, page_block_size, num_heads_kv, head_dim_qk]
+    decode_params.kvcache_batch_stride = params->page_block_size * params->num_heads_kv * params->head_dim_qk;
+    decode_params.kvcache_head_stride = params->head_dim_qk;
+
+    // Split-KV workspace
+    decode_params.splitkv_o_ptr = params->splitkv_out;
+    decode_params.splitkv_lse_ptr = params->splitkv_lse;
+
+    decode_params.stream = stream;
+
+    // Generate scheduling metadata if needed
+    if (!params->metadata_initialized) {
+        GetDecodeSchedMetaParams sched_params;
+        memset(&sched_params, 0, sizeof(sched_params));
+        sched_params.b = params->batch_size;
+        sched_params.h_q = params->num_heads_q;
+        sched_params.page_block_size = params->page_block_size;
+        sched_params.cache_seqlens = params->cache_seqlens;
+        sched_params.block_table = params->block_table;
+        sched_params.block_table_batch_stride = params->block_table_batch_stride;
+        sched_params.tile_scheduler_metadata = (DecodingSchedMeta*)params->tile_scheduler_metadata;
+        sched_params.num_splits = params->num_splits;
+        sched_params.num_sm = params->dprop ? params->dprop->multiProcessorCount : 132;
+
+        flash_mla::run_get_decoding_sched_meta(sched_params, stream);
+    }
+
+    decode_params.tile_scheduler_metadata = (DecodingSchedMeta*)params->tile_scheduler_metadata;
+    decode_params.num_splits = params->num_splits;
+
+    // Dispatch based on dtype and head_dim_qk
+    if (params->dtype == 0) {  // bf16
+        if (params->head_dim_qk == 576) {
+            flash_mla::run_dense_decode_splitkv<__nv_bfloat16, 576>(decode_params, stream);
+        } else if (params->head_dim_qk == 512) {
+            flash_mla::run_dense_decode_splitkv<__nv_bfloat16, 512>(decode_params, stream);
+        } else {
+            return -2;  // unsupported head dim
+        }
+    } else if (params->dtype == 1) {  // fp16
+        if (params->head_dim_qk == 576) {
+            flash_mla::run_dense_decode_splitkv<__half, 576>(decode_params, stream);
+        } else if (params->head_dim_qk == 512) {
+            flash_mla::run_dense_decode_splitkv<__half, 512>(decode_params, stream);
+        } else {
+            return -2;
+        }
+    } else {
+        return -3;  // unsupported dtype
+    }
+
+    // Run combine kernel
+    CombineParams combine_params;
+    memset(&combine_params, 0, sizeof(combine_params));
+    combine_params.b = params->batch_size;
+    combine_params.h_q = params->num_heads_q;
+    combine_params.d_v = params->head_dim_v;
+    combine_params.splitkv_o_ptr = params->splitkv_out;
+    combine_params.splitkv_lse_ptr = params->splitkv_lse;
+    combine_params.o_ptr = params->output;
+    combine_params.num_splits = params->num_splits;
+
+    flash_mla::run_combine(combine_params, stream);
+
+    return 0;
+}
+
+}  // extern "C"
