<div align="center">

[![PyPI](https://img.shields.io/pypi/v/dashinfer)](https://pypi.org/project/dashinfer/)
[![Documentation Status](https://readthedocs.org/projects/dashinfer/badge/?version=latest)](https://dashinfer.readthedocs.io/en/latest/)

<h4 align="center">
    <p>
        <a href="https://github.com/modelscope/dash-infer/blob/main/README.md">English</a> |
        <b>ä¸­æ–‡</b>
    </p>
</h4>


</div>

## æœ€æ–°åŠ¨æ€
- [2026/02] ğŸ”¥ DashInfer v3.0 å‘å¸ƒï¼ä¸»è¦æ–°ç‰¹æ€§åŒ…æ‹¬ï¼šCUDA Graph åŠ é€Ÿ decode é˜¶æ®µã€DeepSeek V3ï¼ˆ671Bï¼‰æ”¯æŒåŠ Multi-Latent Attention (MLA)ã€FP8 (A8W8) é‡åŒ–ï¼ˆHopper GPUï¼‰ã€è¿ç»­æ‰¹å¤„ç† LoRA ä¼˜åŒ–ï¼Œä»¥åŠå¤§è§„æ¨¡ MoE æ¨¡å‹çš„ Expert Parallelism (EP) æ”¯æŒã€‚è¯¦æƒ…è¯·å‚è€ƒ[å‘å¸ƒè¯´æ˜](https://dashinfer.readthedocs.io/en/latest/index.html#v3-0-0)ã€‚

- [2024/12] DashInfer v2.0 å‘å¸ƒï¼Œæ”¯æŒå¢å¼ºçš„ GPUï¼ˆCUDAï¼‰èƒ½åŠ›ï¼ŒåŒ…æ‹¬å‰ç¼€ç¼“å­˜ï¼ˆGPU & CPU äº¤æ¢ï¼‰ã€å¼•å¯¼è§£ç ã€GQA æ³¨æ„åŠ›ä¼˜åŒ–ã€æ— é” reactor å¼•æ“ï¼Œä»¥åŠæ–°å¢ VLM æ¨¡å‹ï¼ˆQwen-VLï¼‰å’Œ MoE æ¨¡å‹æ”¯æŒã€‚

- [2024/06] DashInfer v1.0 å‘å¸ƒï¼Œæ”¯æŒ x86 & ARMv9 CPU ä»¥åŠ CPU flash attentionã€‚

# ç®€ä»‹

DashInferé‡‡ç”¨C++ Runtime ç¼–å†™ï¼Œæä¾›C++ å’Œ Pythonè¯­è¨€æ¥å£ã€‚ DashInfer å…·æœ‰ç”Ÿäº§çº§åˆ«çš„é«˜æ€§èƒ½è¡¨ç°ï¼Œ æ”¯æŒå¤šç§CUDAæ¶æ„ï¼Œ CPUæ¶æ„ã€‚ DashInferæ”¯æŒå¤šç§ä¸»æµLLMæ¨ç†æŠ€æœ¯è¿ç»­æ‰¹å¤„ç†ï¼ˆContinuous Batchingï¼‰ï¼Œæƒé‡é‡åŒ–ï¼Œ KV-Cacheé‡åŒ–ï¼Œ Page Attentionï¼ˆè‡ªç ”SpanAttention Kernelï¼‰ï¼ŒGuided Outputï¼Œ Prefix Cachingã€‚

## ä¸»è¦ç‰¹æ€§
DashInfer æ˜¯ä¸€ä¸ªé«˜åº¦ä¼˜åŒ–çš„ LLM æ¨ç†å¼•æ“ï¼Œå…·æœ‰ä»¥ä¸‹æ ¸å¿ƒç‰¹æ€§ï¼š
- **è½»é‡çº§æ¶æ„**: DashInfer éœ€è¦æœ€å°‘çš„ç¬¬ä¸‰æ–¹ä¾èµ–ï¼Œå¹¶ä½¿ç”¨é™æ€é“¾æ¥å‡ ä¹æ‰€æœ‰çš„ä¾èµ–åº“ã€‚é€šè¿‡æä¾› C++ å’Œ Python æ¥å£ï¼ŒDashInfer å¯ä»¥è½»æ¾é›†æˆåˆ°æ‚¨ç°æœ‰çš„ç³»ç»Ÿä¸­ã€‚
- **é«˜ç²¾åº¦**: DashInfer ç»è¿‡ä¸¥æ ¼æµ‹è¯•ä»¥ç¡®ä¿å‡†ç¡®æ€§ï¼Œèƒ½å¤Ÿæä¾›ä¸ PyTorch å’Œå…¶ä»– GPU å¼•æ“ï¼ˆä¾‹å¦‚ vLLMï¼‰ä¸€è‡´çš„æ¨ç†ç²¾åº¦ã€‚
- **é«˜æ€§èƒ½**: DashInfer é‡‡ç”¨ä¼˜åŒ–çš„å†…æ ¸æä¾›é«˜æ€§èƒ½ LLM æœåŠ¡ï¼ŒåŒæ—¶æ”¯æŒè®¸å¤šæ ‡å‡† LLM æ¨ç†æŠ€æœ¯ï¼ŒåŒ…æ‹¬ï¼š
  - **è¿ç»­æ‰¹å¤„ç†**: DashInfer å…è®¸å³æ—¶æ’å…¥æ–°è¯·æ±‚ï¼Œå¹¶æ”¯æŒæµå¼è¾“å‡ºã€‚
  - **åˆ†é¡µæ³¨æ„åŠ›æœºåˆ¶**: ä½¿ç”¨æˆ‘ä»¬è‡ªç ”çš„åˆ†é¡µæ³¨æ„åŠ›æœºåˆ¶ï¼ˆæˆ‘ä»¬ç§°ä¹‹ä¸º *SpanAttention*ï¼‰ï¼Œç»“åˆåŸºäºé«˜æ•ˆ GEMM å’Œ GEMV å®ç°çš„ int8 å’Œ uint4 KV ç¼“å­˜é‡åŒ–ï¼Œèƒ½å¤Ÿå®ç°æ³¨æ„åŠ›è¿ç®—ç¬¦çš„é«˜æ•ˆåŠ é€Ÿã€‚
  - **CUDA Graph**: DashInfer æ”¯æŒ decode é˜¶æ®µçš„ CUDA Graph æ•è·ï¼Œæ˜¾è‘—å‡å°‘ kernel å¯åŠ¨å¼€é”€ï¼Œæå‡å°æ‰¹é‡/å»¶è¿Ÿæ•æ„Ÿåœºæ™¯çš„ååé‡ã€‚
  - **Multi-Latent Attention (MLA)**: DashInfer æ”¯æŒ MLA æ¶æ„ï¼ˆDeepSeek V3 ä½¿ç”¨ï¼‰ï¼Œé€šè¿‡å‹ç¼© KV Cacheï¼Œç›¸æ¯”æ ‡å‡†å¤šå¤´æ³¨æ„åŠ›å‡å°‘çº¦ 28 å€çš„æ¯ token KV ç¼“å­˜ã€‚
  - **å‰ç¼€ç¼“å­˜**: DashInfer æ”¯æŒé«˜æ•ˆçš„å‰ç¼€ç¼“å­˜ï¼Œç”¨äºåŠ é€Ÿæ ‡å‡† LLMs å’Œå¤šæ¨¡æ€ LMsï¼ˆå¦‚ Qwen-VLï¼‰ï¼Œæ”¯æŒ GPU å’Œ CPUã€‚
  - **é‡åŒ–æ”¯æŒ**: ä½¿ç”¨ DashInfer çš„ *InstantQuant*ï¼ˆIQï¼‰ï¼Œæ— éœ€å¾®è°ƒå³å¯å®ç°æƒé‡é‡åŒ–åŠ é€Ÿï¼Œæé«˜éƒ¨ç½²æ•ˆç‡ã€‚DashInfer è¿˜æ”¯æŒ Hopper GPUï¼ˆSM90+ï¼‰ä¸Šçš„ FP8 (A8W8) é‡åŒ–ï¼Œè¿›ä¸€æ­¥æå‡æ€§èƒ½ã€‚
  - **LoRA**: DashInfer æ”¯æŒè¿ç»­æ‰¹å¤„ç†çš„ LoRA ä¼˜åŒ–ï¼Œæ”¯æŒè¿è¡Œæ—¶åŠ¨æ€åŠ è½½/å¸è½½ LoRA é€‚é…å™¨ï¼Œå®ç°é«˜æ•ˆçš„å¤šç§Ÿæˆ·æœåŠ¡ã€‚
  - **å¼‚æ­¥æ¥å£**: åŸºäºè¯·æ±‚çš„å¼‚æ­¥æ¥å£æä¾›å¯¹æ¯ä¸ªè¯·æ±‚ç”Ÿæˆå‚æ•°å’Œè¯·æ±‚çŠ¶æ€çš„ç‹¬ç«‹æ§åˆ¶ã€‚
- æ”¯æŒçš„æ¨¡å‹ï¼š
  - **ä¸»æµå¼€æº LLMs**: DashInfer æ”¯æŒä¸»æµå¼€æº LLMsï¼ŒåŒ…æ‹¬ Qwenï¼ˆ1/1.5/2/2.5/3ï¼‰ã€LLaMAï¼ˆ2/3ï¼‰ã€ChatGLMã€DeepSeek V3 ç­‰ï¼Œä¸”æ”¯æŒåŠ è½½ Huggingface æ ¼å¼çš„æ¨¡å‹ã€‚
  - **MoE æ¨¡å‹**: DashInfer æ”¯æŒæ··åˆä¸“å®¶æ¨¡å‹ï¼ŒåŒ…æ‹¬ Qwen2-MoE å’Œ DeepSeek V3ï¼ˆ671Bï¼Œ256 ä¸“å®¶ï¼‰ï¼Œæ”¯æŒ Expert Parallelism (EP) è¿›è¡Œå¤š GPU åˆ†å¸ƒå¼æ¨ç†ã€‚
  - **å¤šæ¨¡æ€å¤§æ¨¡å‹(VLMs)**: DashInfer æ”¯æŒå¤šæ¨¡æ€è¯­è¨€æ¨¡å‹ï¼ˆVLMsï¼‰ï¼ŒåŒ…æ‹¬ Qwen-VLã€Qwen-AL å’Œ Qwen2-VLã€‚
- **OpenAI API æœåŠ¡å™¨**: DashInfer å¯ä»¥è½»æ¾ä¸ fastChat é…åˆä½¿ç”¨ï¼Œå®ç°å…¼å®¹ OpenAI çš„ API æœåŠ¡å™¨ã€‚
- **å¤šç¼–ç¨‹è¯­è¨€ API**: æä¾› C++ å’Œ Python æ¥å£ã€‚é€šè¿‡æ ‡å‡†çš„è·¨è¯­è¨€æ¥å£ï¼Œå¯ä»¥å°† C++ æ¥å£æ‰©å±•åˆ° Javaã€Rust ç­‰ç¼–ç¨‹è¯­è¨€ã€‚


# ç¡¬ä»¶æ”¯æŒå’Œæ•°æ®ç±»å‹

## ç¡¬ä»¶æ”¯æŒ
- **CUDA GPU**ï¼šæ”¯æŒ CUDA ç‰ˆæœ¬ä» 11.4 åˆ° 12.9ï¼Œå¹¶æ”¯æŒå¤šç§ CUDA è®¡ç®—æ¶æ„ï¼Œä¾‹å¦‚ SM70 - SM100ï¼ˆT4ã€3090ã€4090ã€V100ã€A100ã€A10ã€L20ã€H20ã€H100ã€B200ï¼‰ã€‚SM100ï¼ˆB200ï¼‰ä¸ºå®éªŒæ€§æ”¯æŒã€‚
- **x86 CPU**ï¼šè¦æ±‚ç¡¬ä»¶è‡³å°‘éœ€è¦æ”¯æŒAVX2æŒ‡ä»¤é›†ã€‚å¯¹äºç¬¬äº”ä»£è‡³å¼ºï¼ˆXeonï¼‰å¤„ç†å™¨ï¼ˆEmerald Rapidsï¼‰ã€ç¬¬å››ä»£è‡³å¼ºï¼ˆXeonï¼‰å¤„ç†å™¨ï¼ˆSapphire Rapidsï¼‰ç­‰ï¼ˆå¯¹åº”äºé˜¿é‡Œäº‘ç¬¬8ä»£ECSå®ä¾‹ï¼Œå¦‚g8iï¼‰ï¼Œé‡‡ç”¨AMXçŸ©é˜µæŒ‡ä»¤åŠ é€Ÿè®¡ç®—ã€‚
- **ARMv9 CPU**ï¼šè¦æ±‚ç¡¬ä»¶æ”¯æŒSVEæŒ‡ä»¤é›†ã€‚æ”¯æŒå¦‚å€šå¤©ï¼ˆYitianï¼‰710ç­‰ARMv9æ¶æ„å¤„ç†å™¨ï¼ˆå¯¹åº”äºé˜¿é‡Œäº‘ç¬¬8ä»£ECSå®ä¾‹ï¼Œå¦‚g8yï¼‰ï¼Œé‡‡ç”¨SVEå‘é‡æŒ‡ä»¤åŠ é€Ÿè®¡ç®—ã€‚

## æ•°æ®ç±»å‹
- **CUDA GPUs**: FP16, BF16, FP8, FP32, Int8(InstantQuant), Int4(InstantQuant)
- **x86 CPU**ï¼šæ”¯æŒFP32ã€BF16ã€‚
- **ARM Yitian710 CPU**ï¼šFP32ã€BF16ã€InstantQuantã€‚

### InstantQuant
DashInfer ä¸º LLM æƒé‡æä¾›äº†å¤šç§é‡åŒ–æŠ€æœ¯ï¼Œä¾‹å¦‚ int{8,4} ä»…æƒé‡é‡åŒ–ã€int8 æ¿€æ´»é‡åŒ–ï¼Œè¿˜æœ‰è®¸å¤šå®šåˆ¶çš„èåˆå†…æ ¸ï¼Œä»¥åœ¨æŒ‡å®šè®¾å¤‡ä¸Šæä¾›æœ€ä½³æ€§èƒ½ã€‚ç®€è€Œè¨€ä¹‹ï¼Œä½¿ç”¨ GPTQ å¾®è°ƒçš„æ¨¡å‹å°†æä¾›æ›´å¥½çš„å‡†ç¡®æ€§ï¼Œè€Œæˆ‘ä»¬æ— éœ€å¾®è°ƒçš„ InstantQuant (IQ) æŠ€æœ¯å¯æä¾›æ›´å¿«çš„éƒ¨ç½²ä½“éªŒã€‚IQ é‡åŒ–çš„è¯¦ç»†è§£é‡Šå¯ä»¥åœ¨æœ¬æ–‡æœ«å°¾æ‰¾åˆ°ã€‚

åœ¨æ”¯æŒçš„é‡åŒ–ç®—æ³•æ–¹é¢ï¼ŒAllSpark é€šè¿‡ä¸¤ç§æ–¹å¼æ”¯æŒä½¿ç”¨ GPTQ å¾®è°ƒçš„æ¨¡å‹å’Œä½¿ç”¨ IQ é‡åŒ–æŠ€æœ¯çš„åŠ¨æ€é‡åŒ–ï¼š
- **InstantQuant (IQ)**: DashInfer æä¾›äº† InstantQuant (IQ) åŠ¨æ€é‡åŒ–æŠ€æœ¯ï¼Œæ— éœ€å¾®è°ƒå³å¯æä¾›æ›´å¿«çš„éƒ¨ç½²ä½“éªŒã€‚IQ é‡åŒ–çš„è¯¦ç»†è§£é‡Šå¯ä»¥åœ¨æœ¬æ–‡æœ«å°¾æ‰¾åˆ°ã€‚
- **GPTQ**: ä½¿ç”¨ GPTQ å¾®è°ƒçš„æ¨¡å‹å°†æä¾›æ›´å¥½çš„å‡†ç¡®æ€§ï¼Œä½†å®ƒéœ€è¦ä¸€ä¸ªå¾®è°ƒæ­¥éª¤ã€‚

è¿™é‡Œä»‹ç»çš„é‡åŒ–ç­–ç•¥å¤§è‡´å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼š
- **ä»…æƒé‡é‡åŒ–**: è¿™ç§é‡åŒ–æŠ€æœ¯ä»…å¯¹æƒé‡è¿›è¡Œé‡åŒ–å’Œå‹ç¼©ï¼Œä¾‹å¦‚ä»¥ int8 æ ¼å¼å­˜å‚¨æƒé‡ï¼Œä½†åœ¨è®¡ç®—æ—¶ä»æ—§ä½¿ç”¨ bf16/fp16ã€‚å®ƒåªæ˜¯å‡å°‘äº†å†…å­˜è®¿é—®éœ€æ±‚ï¼Œç›¸æ¯” BF16 å¹¶æ²¡æœ‰æé«˜è®¡ç®—æ€§èƒ½ã€‚
- **æ¿€æ´»é‡åŒ–**: è¿™ç§é‡åŒ–æŠ€æœ¯ä¸ä»…ä»¥ int8 æ ¼å¼å­˜å‚¨æƒé‡ï¼Œè¿˜åœ¨è®¡ç®—é˜¶æ®µæ‰§è¡Œä½ç²¾åº¦é‡åŒ–è®¡ç®—ï¼ˆå¦‚ int8ï¼‰ã€‚ç”±äº Nvidia GPU åªæœ‰ int8 Tensor Core å®¹æ˜“ä¿æŒç²¾åº¦ï¼Œè¿™ç§é‡åŒ–æŠ€æœ¯æ—¢èƒ½å‡å°‘å†…å­˜è®¿é—®éœ€æ±‚ï¼Œåˆèƒ½æé«˜è®¡ç®—æ€§èƒ½ï¼Œä½¿å…¶æˆä¸ºç†æƒ³çš„é‡åŒ–æ–¹æ³•ã€‚åœ¨å‡†ç¡®æ€§æ–¹é¢ï¼Œå®ƒç›¸æ¯”ä»…æƒé‡é‡åŒ–å¯èƒ½ä¼šæœ‰è½»å¾®ä¸‹é™ï¼Œå› æ­¤éœ€è¦ä¸šåŠ¡æ•°æ®çš„å‡†ç¡®æ€§æµ‹è¯•ã€‚

åœ¨é‡åŒ–ç²’åº¦æ–¹é¢ï¼Œæœ‰ä¸¤ç§ç±»å‹ï¼š
- **æ¯é€šé“é‡åŒ–**: DashInfer çš„é‡åŒ–æŠ€æœ¯è‡³å°‘é‡‡ç”¨äº†æ¯é€šé“ï¼ˆä¹Ÿç§°ä¸ºæ¯ Tokenï¼‰é‡åŒ–ç²’åº¦ï¼Œæœ‰äº›è¿˜æä¾›äº†å­é€šé“é‡åŒ–ç²’åº¦ã€‚ä¸€èˆ¬è€Œè¨€ï¼Œæ¯é€šé“é‡åŒ–ç”±äºå®ç°ç®€å•ä¸”æ€§èƒ½æœ€ä½³ï¼Œé€šå¸¸èƒ½æ»¡è¶³å¤§å¤šæ•°å‡†ç¡®æ€§éœ€æ±‚ã€‚åªæœ‰å½“æ¯é€šé“é‡åŒ–çš„å‡†ç¡®æ€§ä¸è¶³æ—¶ï¼Œæ‰åº”è€ƒè™‘å­é€šé“é‡åŒ–ç­–ç•¥ã€‚
- **å­é€šé“é‡åŒ–**: ä¸æ¯é€šé“é‡åŒ–ç›¸æ¯”ï¼Œå­é€šé“é‡åŒ–æ˜¯æŒ‡å°†ä¸€ä¸ªé€šé“åˆ’åˆ†ä¸º N ç»„ï¼Œå¹¶åœ¨æ¯ç»„å†…è®¡ç®—é‡åŒ–å‚æ•°ã€‚è¿™ç§é‡åŒ–ç²’åº¦é€šå¸¸èƒ½æä¾›æ›´å¥½çš„å‡†ç¡®æ€§ï¼Œä½†ç”±äºå®ç°å¤æ‚åº¦å¢åŠ ï¼Œå¸¦æ¥äº†è®¸å¤šé™åˆ¶ã€‚ä¾‹å¦‚ï¼Œæ€§èƒ½å¯èƒ½æ¯”æ¯é€šé“é‡åŒ–ç¨æ…¢ï¼Œå¹¶ä¸”ç”±äºè®¡ç®—å…¬å¼é™åˆ¶ï¼Œæ¿€æ´»é‡åŒ–éš¾ä»¥å®ç°å­é€šé“é‡åŒ–ï¼ˆDashInferçš„æ¿€æ´»é‡åŒ–éƒ½æ˜¯æ¯é€šé“é‡åŒ–ï¼‰ã€‚

# è½¯ä»¶ä¾èµ–

## æ„å»ºä¾èµ–

DashInfer ä½¿ç”¨ [Conan 2.x](https://conan.io/) ç®¡ç† C++ ç¬¬ä¸‰æ–¹ä¾èµ–ã€‚ä¸»è¦ä¾èµ–åŒ…æ‹¬ï¼š

| ä¾èµ– | ç‰ˆæœ¬ |
|---|---|
| Conan | >= 2.0 |
| protobuf | 3.18.3 |
| gtest | 1.11.0 |
| glog | 0.5.0 |
| pybind11 | 2.13.6 |
| zlib | 1.2.13 |

> æ³¨æ„ï¼šConan 1.x å·²ä¸å†æ”¯æŒï¼Œè¯·å‡çº§åˆ° Conan 2.xï¼š`pip install "conan>=2.0"`

## è¿è¡Œæ—¶ä¾èµ–
1. **Python**ï¼š DashInfer Python åŒ…ä¾èµ– PyTorch å’Œ Huggingface Transformersï¼ˆç”¨äº safetensors æ¨¡å‹æƒé‡åŠ è½½ï¼‰ï¼Œä½†ç”±äºè¿è¡Œæ—¶éœ€è¦è°ƒç”¨ HF æ¥å£è¿›è¡Œæ¨¡å‹æƒé‡åŠ è½½ï¼Œå„ä¸ªæ¨¡å‹å¯èƒ½æœ‰è‡ªå·±çš„é¢å¤–ä¾èµ–ã€‚
2. **C++**: ç›®å‰ C++ åŒ…å…¨éƒ¨é™æ€ç¼–è¯‘äº†ç¬¬ä¸‰æ–¹ä¾èµ–åº“ï¼Œå¹¶ä¸”åšäº†ç¬¦å·éšè—ï¼Œæ‰€ä»¥ç›®å‰ C++ åŒ…æ— ä»»ä½•ç¬¬ä¸‰æ–¹åº“çš„è¿è¡Œæ—¶ä¾èµ–ã€‚


# æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç 

## æ–‡æ¡£

è¯¦ç»†çš„ç”¨æˆ·æ‰‹å†Œè¯·å‚è€ƒæ–‡æ¡£ï¼š [æ–‡æ¡£åœ°å€](https://dashinfer.readthedocs.io/en/latest/)ã€‚

### Quick Start:

1. APIä½¿ç”¨ [Python Quick Start](https://dashinfer.readthedocs.io/en/latest/get_started/quick_start_api_py_en.html)
2. LLM OpenAI Server [Quick Start Guide for OpenAI API Server](https://dashinfer.readthedocs.io/en/latest/get_started/quick_start_api_server_en.html)
3. VLM OpenAI Server [VLM Support](https://dashinfer.readthedocs.io/en/latest/vlm/vlm_offline_inference_en.html)

### Featureä»‹ç»ï¼š

1. [Prefix Cache](https://dashinfer.readthedocs.io/en/latest/llm/prefix_caching.html)
2. [Guided Decoding](https://dashinfer.readthedocs.io/en/latest/llm/guided_decoding.html)
3. [Engine Config](https://dashinfer.readthedocs.io/en/latest/llm/runtime_config.html)

### å¼€å‘ç›¸å…³ï¼š

1. [Development Guide](https://dashinfer.readthedocs.io/en/latest/devel/source_code_build_en.html#)
2. [Build From Source](https://dashinfer.readthedocs.io/en/latest/devel/source_code_build_en.html#build-from-source-code)
3. [OP Profiling](https://dashinfer.readthedocs.io/en/latest/devel/source_code_build_en.html#profiling)
4. [Environment Variable](https://dashinfer.readthedocs.io/en/latest/get_started/env_var_options_en.html)
 
##  ä»£ç ç¤ºä¾‹

åœ¨`<path_to_dashinfer>/examples`ä¸‹æä¾›äº†C++ã€pythonæ¥å£çš„è°ƒç”¨ç¤ºä¾‹ï¼Œè¯·å‚è€ƒ`<path_to_dashinfer>/docs/CN`ç›®å½•ä¸‹çš„æ–‡æ¡£è¿è¡Œç¤ºä¾‹ã€‚

- [æ‰€æœ‰Pythonç¤ºä¾‹æ–‡æ¡£](docs/CN/examples_python.md)
- [C++ç¤ºä¾‹æ–‡æ¡£](docs/CN/examples_cpp.md)
- [Python Benchmark](https://github.com/modelscope/dash-infer/tree/main/examples/benchmark)

## å¤šæ¨¡æ€æ¨¡å‹æ”¯æŒ

[multimodal](multimodal/) ç›®å½•ä¸‹æ˜¯åŸºäºDashInferå®ç°çš„å¤šæ¨¡æ€æ¨¡å‹æ¨ç†å·¥å…·ï¼Œå…¼å®¹OpenAI Chat Completion APIï¼Œæ”¯æŒæ–‡å­—ã€å›¾ç‰‡ã€è§†é¢‘è¾“å…¥ã€‚

# æ€§èƒ½

æˆ‘ä»¬è¿›è¡Œäº†ä¸€ç³»åˆ—åŸºå‡†æµ‹è¯•ï¼Œä»¥æ¯”è¾ƒä¸»æµ LLM æ¨ç†å¼•æ“çš„æ€§èƒ½ã€‚

### å¤šæ¨¡æ€æ¨¡å‹ (VLMs)

æˆ‘ä»¬æ¯”è¾ƒäº†ä¸åŒè§„æ¨¡æ¨¡å‹ä¸‹ Qwen-VL ä¸ vllm çš„æ€§èƒ½ï¼š

![img_1.png](docs/resources/image/dashinfer-benchmark-vl.png)

åŸºå‡†æµ‹è¯•ä½¿ç”¨äº† A100-80Gx1 æµ‹è¯• 2B å’Œ 7B æ¨¡å‹ï¼Œä½¿ç”¨ A100-80Gx4 æµ‹è¯• 72B æ¨¡å‹ã€‚æ›´å¤šè¯¦æƒ…ï¼Œè¯·å‚è€ƒ[åŸºå‡†æ–‡æ¡£](https://github.com/modelscope/dash-infer/blob/main/multimodal/tests/README.md)ã€‚

## Prefix Cache

æˆ‘ä»¬è¯„ä¼°äº†åœ¨ä¸åŒç¼“å­˜å‘½ä¸­ç‡ä¸‹å‰ç¼€ç¼“å­˜çš„æ€§èƒ½ï¼š

![dahsinfer-benchmark-prefix-cache.png](docs/resources/image/dahsinfer-benchmark-prefix-cache.png)

ä¸Šå›¾æ˜¾ç¤ºäº† DashInfer ä¸­ TTFTï¼ˆé¦–æ¬¡ç”Ÿæˆ Token çš„æ—¶é—´ï¼‰éšç€ä¸åŒ PrefixCache å‘½ä¸­ç‡çš„å‡å°‘æƒ…å†µã€‚

![dashinfer-prefix-effect.png](docs/resources/image/dashinfer-prefix-effect.png)

**æµ‹è¯•è®¾ç½®ï¼š**  
- **æ¨¡å‹ï¼š** Qwen2-72B-Instruct  
- **GPUï¼š** 4x A100  
- **è¿è¡Œæ¬¡æ•°ï¼š** 20  
- **æ‰¹å¤„ç†å¤§å°ï¼š** 1  
- **è¾“å…¥ Tokensï¼š** 4000  
- **è¾“å‡º Tokensï¼š** 1  

## Guided Decode

æˆ‘ä»¬åœ¨ç›¸åŒè¯·æ±‚ä¸‹ä½¿ç”¨è‡ªå®šä¹‰ JSON æ¶æ„ï¼ˆA100x1 7B Qwen, ä¸Šä¸‹æ–‡é•¿åº¦ï¼š45ï¼Œç”Ÿæˆé•¿åº¦ï¼š63ï¼‰ï¼Œæ¯”è¾ƒäº†ä¸åŒå¼•æ“çš„Guided Decodeçš„æ€§èƒ½ï¼Œå›¾ä¸­æ•°æ®ä¸ºæ•´ä½“RT ï¼š

![dashinfer-benchmark-json-mode.png](docs/resources/image/dashinfer-benchmark-json-mode.png)

# å­é¡¹ç›®

1. [HIE-DNN](https://github.com/modelscope/dash-infer/tree/main/HIE-DNN) ä¸º DashInfer æ‰€ä½¿ç”¨çš„ç®—å­åº“ã€‚
2. [SpanAttention](https://github.com/modelscope/dash-infer/tree/main/span-attention) ä¸º DashInfer GPU å®ç°çš„åˆ†é¡µ attention ç®—å­ã€‚

# å¼•ç”¨

DashInfer çš„é«˜æ€§èƒ½ MoE ç®—å­åŸºäº [è¿™ç¯‡è®ºæ–‡](https://arxiv.org/abs/2501.16103) å®ç°ï¼Œæ­¤å¤–ï¼ŒDashInfer ä½¿ç”¨äº†é«˜æ•ˆçš„ top-k ç®—å­ [*RadiK*](https://arxiv.org/abs/2501.14336).
å¦‚æœæˆ‘ä»¬çš„å·¥ä½œå¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨ï¼š

```bibtex
@misc{dashinfermoe2025,
  title = {Static Batching of Irregular Workloads on GPUs: Framework and Application to Efficient MoE Model Inference}, 
  author = {Yinghan Li and Yifei Li and Jiejing Zhang and Bujiao Chen and Xiaotong Chen and Lian Duan and Yejun Jin and Zheng Li and Xuanyu Liu and Haoyu Wang and Wente Wang and Yajie Wang and Jiacheng Yang and Peiyang Zhang and Laiwen Zheng and Wenyuan Yu},
  year = {2025},
  eprint = {2501.16103},
  archivePrefix = {arXiv},
  primaryClass = {cs.DC},
  url = {https://arxiv.org/abs/2501.16103}
}

@inproceedings{radik2024,
  title = {RadiK: Scalable and Optimized GPU-Parallel Radix Top-K Selection},
  author = {Li, Yifei and Zhou, Bole and Zhang, Jiejing and Wei, Xuechao and Li, Yinghan and Chen, Yingda},
  booktitle = {Proceedings of the 38th ACM International Conference on Supercomputing},
  year = {2024}
}
```

# è·¯çº¿å›¾

## å·²å®Œæˆ
- [x] GPU æ”¯æŒ
- [x] å¤šæ¨¡æ€æ¨¡å‹æ”¯æŒ
- [x] Flash-Attention åŠ é€Ÿ
- [x] ä¸Šä¸‹æ–‡é•¿åº¦æ‰©å±•è‡³ 32k ä»¥ä¸Š
- [x] 4-bit é‡åŒ–æ”¯æŒ
- [x] GPTQ å¾®è°ƒæ¨¡å‹æ”¯æŒ
- [x] MoE æ¶æ„æ”¯æŒ
- [x] å¼•å¯¼è¾“å‡ºï¼šJSON Mode
- [x] Prefix Cacheï¼šGPU å‰ç¼€ç¼“å­˜ä¸ CPU äº¤æ¢
- [x] é‡åŒ–ï¼šCUDA FP8 A8W8 æ¿€æ´»é‡åŒ–
- [x] LoRAï¼šè¿ç»­æ‰¹å¤„ç† LoRA ä¼˜åŒ–
- [x] å¼•æ“å†… Context é˜¶æ®µä¸ Generation é˜¶æ®µå¹¶è¡Œ
- [x] æ›´é«˜æ•ˆçš„ GPU MoE ç®—å­
- [x] CUDA Graphï¼šdecode é˜¶æ®µåˆ†æ®µ CUDA Graph æ•è·åŠ é€Ÿ
- [x] MLAï¼šMulti-Latent Attention æ”¯æŒï¼ˆDeepSeek V3ï¼‰
- [x] Expert Parallelism (EP) å¤§è§„æ¨¡ MoE æ¨¡å‹æ”¯æŒ

## è¿›è¡Œä¸­ & è®¡åˆ’ä¸­

### [æ€§èƒ½ä¼˜åŒ–](docs/EN/roadmap_performance.md)
ç›®æ ‡ï¼šåœ¨ dense 72B æ¨¡å‹ï¼ˆH100ï¼‰å’Œ DeepSeek V3.2ï¼ˆB200ï¼‰ä¸Šè¿½å¹³ vLLM/SGLang ååã€‚
- [ ] Chunked Prefill + ç»Ÿä¸€è°ƒåº¦å™¨
- [ ] CUDA Graph Full æ•è·ï¼ˆdecode é˜¶æ®µï¼‰
- [ ] æŠ•æœºè§£ç ï¼ˆEAGLEï¼‰
- [ ] DP Attentionï¼ˆæ•°æ®å¹¶è¡Œ Attentionï¼Œç”¨äº MoE + MLAï¼‰
- [ ] FP4 MoE èåˆç®—å­ï¼ˆBlackwell B200ï¼‰
- [ ] NSA ç®—å­èåˆï¼ˆDeepSeek V3.2 Native Sparse Attentionï¼‰

### [RL è®­ç»ƒé›†æˆ](docs/EN/roadmap_rl_integration.md)
ç›®æ ‡ï¼šä½¿ DashInfer æˆä¸º RLHF/GRPO/DPO è®­ç»ƒçš„æ¨ç†åç«¯ï¼ˆOpenRLHFã€veRLã€TRLï¼‰ã€‚
- [ ] Prompt Logprobsï¼ˆprefill é˜¶æ®µ log probabilitiesï¼‰
- [ ] æƒé‡çƒ­æ›´æ–°ï¼ˆæ— éœ€é‡å¯å¼•æ“ï¼‰
- [ ] Sleep/Wake æ¨¡å¼ï¼ˆè®­ç»ƒæ—¶è®©å‡º GPU æ˜¾å­˜ï¼‰
- [ ] è®­ç»ƒ-æ¨ç†åŒå¡å…±å­˜
- [ ] Ray / åˆ†å¸ƒå¼è°ƒåº¦æ¡†æ¶é›†æˆ

### å…¶ä»–
- [ ] AMD (ROCm) å¹³å°é€‚é…
- [ ] [åŸºç¡€è®¾æ–½å‡çº§](docs/EN/roadmap_infra_upgrade.md)ï¼šFlash Attention 3/4 å‡çº§ã€CUTLASS å‡çº§ã€Docker é•œåƒç°ä»£åŒ–ã€Conan 2.xã€Python 3.10+ é»˜è®¤

# License

DashInferæºä»£ç é‡‡ç”¨Apache 2.0åè®®æˆæƒï¼Œæ‚¨å¯åœ¨è¯¥ä»“åº“æ ¹ç›®å½•æ‰¾åˆ°åè®®å…¨æ–‡ã€‚
